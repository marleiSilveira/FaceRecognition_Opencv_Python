1 -
-------------
import cv2

# Captura imagem da webcan
"""
O dispositivo que far� a captura � passado pelo par�metro.
Se par�metro = 0, ent�o o dispositivo � padr�o, ou seja, a c�mera do pr�prio notebook.
Se houver mais de uma c�mera, ent�o coloque: 0 para o 1�, 1 para o 2�, ...
"""
camera = cv2.VideoCapture(0)

while (True): # Loop infinito
    conectado, imagem = camera.read() # Faz a leitura da Webcan, � partir da var 'camera'

    cv2.imshow("Face", imagem) # imshow: mostra iamgem capturada da webcan; imagen: vari�vel da captura
    cv2.waitKey(1)

camera.release() # release: libera a mem�ria
cv2.destroyAllWindows()
---------------

2

import cv2

# Classificador � treinado por haarcascade
classificador = cv2.CascadeClassifier("haarcascade-frontalface-default.xml") # Carrega o arquivo para treinamento
# Captura imagem da webcan
"""
O dispositivo que far� a captura � passado pelo par�metro.
Se par�metro = 0, ent�o o dispositivo � padr�o, ou seja, a c�mera do pr�prio notebook.
Se houver mais de uma c�mera, ent�o coloque: 0 para o 1�, 1 para o 2�, ...
"""
camera = cv2.VideoCapture(0)

while (True):  # Loop infinito
    conectado, imagem = camera.read()  # Faz a leitura da Webcan, � partir da var 'camera'
    imagemCinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY) # Converte imagem para escala de cinza
    '''
       facesdetectadas: set de faces que o algoritimo encontrou; � uma matriz que possui posi��es: x, y, l, a
       x = inicio da face
       y = t�rmino da face
       L = largura da face
       a = altura da face
       imagemCinza: imagem que quero detectar
       scaleFactor: defini��o da escala da imagem via webcan
       minSize: tamanho m�nimo da imagem 
    '''
    facesDetectadas = classificador.detectMultiScale(imagemCinza,
                                                     scaleFactor=1.5,
                                                     minSize=(100, 100))
    for(x, y, l, a) in facesDetectadas: # faz o ret�ngulo ao redor da face;
        '''
        .rectangulo: usa a imagem colorida para a detec��o
        (0, 0, 225) = vermelho
        2 = borda
        '''
        cv2.rectangle(imagem, (x, y), (x + l, y + a), (0, 0, 255), 2)

    cv2.imshow("Face", imagem)  # imshow: mostra iamgem capturada da webcan; imagen: vari�vel da captura
    cv2.waitKey(1)

camera.release()  # release: libera a mem�ria
cv2.destroyAllWindows()

-----------

3

import cv2

# Classificador � treinado por haarcascade
classificador = cv2.CascadeClassifier("haarcascade-frontalface-default.xml") # Carrega o arquivo para treinamento
# Captura imagem da webcan
"""
O dispositivo que far� a captura � passado pelo par�metro.
Se par�metro = 0, ent�o o dispositivo � padr�o, ou seja, a c�mera do pr�prio notebook.
Se houver mais de uma c�mera, ent�o coloque: 0 para o 1�, 1 para o 2�, ...
"""
camera = cv2.VideoCapture(0)
amostra = 1 # Controla quantas fotos foram tiradas
numeroAmostras = 25 # Tirar 25 fotos de cada pessoa (usar sempre mais de 25)
id = input('Digite seu Identificador') # IP da pessoa: 1, 2, 3...
'''
formato da imagem: 
    pessoa.<id>.<numerofoto>.jpg
'''
largura, altura = 220, 220 # Padroniza o tamanho da imagem, pois o eigen-fisherFace, precisam de imagem de tam padr�o
print('Capturando as faces... ')

while (True):  # Loop infinito
    conectado, imagem = camera.read()  # Faz a leitura da Webcan, � partir da var 'camera'
    imagemCinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY) # Converte imagem para escala de cinza
    '''
       facesdetectadas: set de faces que o algoritimo encontrou; � uma matriz que possui posi��es: x, y, l, a
       x = inicio da face
       y = t�rmino da face
       L = largura da face
       a = altura da face
       imagemCinza: imagem que quero detectar
       scaleFactor: defini��o da escala da imagem via webcan
       minSize: tamanho m�nimo da imagem 
    '''
    facesDetectadas = classificador.detectMultiScale(imagemCinza,
                                                     scaleFactor=1.5,
                                                     minSize=(150, 150))
    for(x, y, l, a) in facesDetectadas: # faz o ret�ngulo ao redor da face;
        '''
        .rectangulo: usa a imagem colorida para a detec��o
        (0, 0, 225) = vermelho
        2 = borda
        '''
        cv2.rectangle(imagem, (x, y), (x + l, y + a), (0, 0, 255), 2)
        '''
         C�digo para salvar imagem, pois se ele entra no for significa que est� encontrando a face
         0xff: cod exadecimal, sempre que 'q' for apertada faz uma imagem
         .resize: redimencionamento de img
         .imwrite(): monta o path do arq
        '''
        if(cv2.waitKey(1)) & 0xFF == ord('q'):
            imagemFace = cv2.resize(imagemCinza[y:y + a, x:x + l], (largura, altura))
            cv2.imwrite("fotos/pessoa." + str(id) + "." + str(amostra) + ".jpg", imagemFace)
            print("[foto " + str(amostra) + "capturada com sucesso]")
            amostra +=1 #incrementa��o

    cv2.imshow("Face", imagem)  # imshow: mostra iamgem capturada da webcan; imagen: vari�vel da captura
    #cv2.waitKey(1) # 1: esperando uma tecla, s� coloque um .waitkeyneste codigo
    if(amostra >= numeroAmostras + 1):
        break # stop a captura da tela

print("Faces capturadas com sucesso")
camera.release()  # release: libera a mem�ria
cv2.destroyAllWindows()

-----------------------
4

import cv2
import numpy as np

# Classificador � treinado por haarcascade
classificador = cv2.CascadeClassifier("haarcascade-frontalface-default.xml") # Carrega o arquivo para treinamento
classificadorOlho = cv2.CascadeClassifier("haarcascade-eye.xml") # Carrega arq para treinamento em detec��o de olhos
# Captura imagem da webcan
"""
O dispositivo que far� a captura � passado pelo par�metro.
Se par�metro = 0, ent�o o dispositivo � padr�o, ou seja, a c�mera do pr�prio notebook.
Se houver mais de uma c�mera, ent�o coloque: 0 para o 1�, 1 para o 2�, ...
"""
camera = cv2.VideoCapture(0)
amostra = 1 # Controla quantas fotos foram tiradas
numeroAmostras = 25 # Tirar 25 fotos de cada pessoa (usar sempre mais de 25)
id = input('Digite seu Identificador') # IP da pessoa: 1, 2, 3...
'''
formato da imagem: 
    pessoa.<id>.<numerofoto>.jpg
'''
largura, altura = 220, 220 # Padroniza o tamanho da imagem, pois o eigen-fisherFace, precisam de imagem de tam padr�o
print('Capturando as faces... ')

while (True):  # Loop infinito
    conectado, imagem = camera.read()  # Faz a leitura da Webcan, � partir da var 'camera'
    imagemCinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY) # Converte imagem para escala de cinza
    #print(np.average(imagemCinza)) # Primeiro coloca esse cod no if l� em baixo
    '''
       facesdetectadas: set de faces que o algoritimo encontrou; � uma matriz que possui posi��es: x, y, l, a
       x = inicio da face
       y = t�rmino da face
       L = largura da face
       a = altura da face
       imagemCinza: imagem que quero detectar
       scaleFactor: defini��o da escala da imagem via webcan
       minSize: tamanho m�nimo da imagem 
    '''
    facesDetectadas = classificador.detectMultiScale(imagemCinza,
                                                     scaleFactor=1.5,
                                                     minSize=(150, 150))
    for(x, y, l, a) in facesDetectadas: # faz o ret�ngulo ao redor da face;
        '''
        .rectangulo: usa a imagem colorida para a detec��o
        (0, 0, 225) = vermelho
        2 = borda
        '''
        cv2.rectangle(imagem, (x, y), (x + l, y + a), (0, 0, 255), 2)
        regiao = imagem[y:y + a, x:x + l] # Ver se tem olhos na regiao da face que ele detectou anteriormente
        regiaoCinzaOlho = cv2.cvtColor(regiao, cv2.COLOR_BGR2GRAY) # Convertendo a regiao para escala de cinza
        olhosDetectados = classificadorOlho.detectMultiScale(regiaoCinzaOlho) # detecta o olho
        # Desenha ret�ngulo ao redor dos olhos
        for(ox, oy, ol, oa) in olhosDetectados:
            cv2.rectangle(regiao, (ox, oy), (ox + ol, oy + oa), (0, 225, 0), 2) # Desenha o retangulo na imagem colorida
            '''
            C�digo para salvar imagem, pois se ele entra no for significa que est� encontrando a face
            0xff: cod exadecimal, sempre que 'q' for apertada faz uma imagem
            .resize: redimencionamento de img
            .imwrite(): monta o path do arq
            '''
            if(cv2.waitKey(1)) & 0xFF == ord('q'): # S� entra aqui se detectar a face e olhos
                # if colocado ap�s import numpy, s� entra se a imagem for clara
                if np.average(imagemCinza) > 110: # imgcinza = img da webcan, se vlr < 110, ela � mais escura
                    imagemFace = cv2.resize(imagemCinza[y:y + a, x:x + l], (largura, altura))
                    cv2.imwrite("fotos/pessoa." + str(id) + "." + str(amostra) + ".jpg", imagemFace)
                    print("[foto " + str(amostra) + "capturada com sucesso]")
                    amostra +=1 #incrementa��o

    cv2.imshow("Face", imagem)  # imshow: mostra iamgem capturada da webcan; imagen: vari�vel da captura
    cv2.waitKey(1) # 1: esperando uma tecla
    if(amostra >= numeroAmostras + 1):
        break # stop a captura da tela

print("Faces capturadas com sucesso")
camera.release()  # release: libera a mem�ria
cv2.destroyAllWindows()
-----------
5

import numpy as np

eigenfaces = cv2.face_EigenFaceRecognizer()
fisherface = cv2.face_FisherFaceRecognizer()
lbph = cv2.face_LBPHFaceRecognizer()

def getImagemComId():
    caminhos = [os.path.join('fotos', f) for f in os.listdir('fotos')] # lista de caminhos da foto \\...
    # print(caminhos)
    #
    faces = [] # lista inicializada com vazio; guarda apenas as faces
    ids = []  # lista inicializada com vazio; guarda apenas o ID de cada pessoa
    for caminhoImagem in caminhos:
        imagemFace = cv2.imread(caminhoImagem) # ler o path da img e colocar na var
        #cv2.imshow("Face", imagemFace) # se rodar e aparecer cada imagem, quer dizer q a linha àcima stá ok
        #cv2.waitKey(10) # milisegundos

getImagemComId()


----------------
6

import cv2
import os # recursos sistema operacional
import numpy as np

eigenfaces = cv2.face_EigenFaceRecognizer()
fisherface = cv2.face_FisherFaceRecognizer()
lbph = cv2.face_LBPHFaceRecognizer()

def getImagemComId():
    caminhos = [os.path.join('fotos', f) for f in os.listdir('fotos')] # lista de caminhos da foto \\...
    # print(caminhos)
    #
    faces = [] # lista inicializada com vazio; guarda apenas as faces
    ids = []  # lista inicializada com vazio; guarda apenas o ID de cada pessoa
    for caminhoImagem in caminhos:
        imagemFace = cv2.cvtColor(cv2.imread(caminhoImagem), cv2.COLOR_BGR2GRAY) # ler o path da img, põe em cinza
        id = int(os.path.split(caminhoImagem)[-1].split('.')[1]) # Capturar IPs
        ids.append(id) # coloca na lista
        faces.append(imagemFace)
        # print(id)
        #cv2.imshow("Face", imagemFace) # se rodar e aparecer cada imagem, quer dizer q a linha àcima stá ok
        #cv2.waitKey(10) # milisegundos
    return np.array(ids), faces #converte a lista em np.array

ids, faces = getImagemComId()
print(faces)

-------------
7

import cv2
import os # recursos sistema operacional
import numpy as np

eigenfaces = cv2.face_EigenFaceRecognizer()
fisherface = cv2.face_FisherFaceRecognizer()
lbph = cv2.face_LBPHFaceRecognizer()

def getImagemComId():
    caminhos = [os.path.join('fotos', f) for f in os.listdir('fotos')] # lista de caminhos da foto \\...
    # print(caminhos)
    #
    faces = [] # lista inicializada com vazio; guarda apenas as faces
    ids = []  # lista inicializada com vazio; guarda apenas o ID de cada pessoa
    for caminhoImagem in caminhos:
        imagemFace = cv2.cvtColor(cv2.imread(caminhoImagem), cv2.COLOR_BGR2GRAY) # ler o path da img, põe em cinza
        id = int(os.path.split(caminhoImagem)[-1].split('.')[1]) # Capturar IPs
        ids.append(id) # coloca na lista
        faces.append(imagemFace)
        # print(id)
        #cv2.imshow("Face", imagemFace) # se rodar e aparecer cada imagem, quer dizer q a linha àcima stá ok
        #cv2.waitKey(10) # milisegundos
    return np.array(ids), faces #converte a lista em np.array

ids, faces = getImagemComId()
#print(faces)
print("treinando...")
eigenfaces.train(faces, ids) #lê as imagens e faz o aprendizado supervisionado com as labels
eigenfaces.write('classificadorEigen.yml') # arquivo que é gerado para reconhecimento facial

fisherface.train(faces, ids)
fisherface.write('classificadorFisher.yml')

lbph.train(faces, ids)
lbph.write('classificadorLBPH.yml')

print("Treinamento realizado")







